%************************************************
\chapter[Similarités et objets]{Similarités et objets: application au recouvrement des similarités acoustiques}\label{ch:ml_xp}
%************************************************


\section{Introduction}
\label{sec:ch8_intro}

\gl{TODO: bag-frame et early integration} \\ 

\gl{TODO: or Une perception basée sur l'objet} \\ 

\gl{TODO: cependant performances des systèmes de détection faibles} \\

\section{Le bag-of-frame: une approche non satisfaisante}


\section{Une représentation basée sur l'objet}

\subsection{Formation des objets}

\subsection{Similarité entres objets}

\subsection{Coefficients de Scattering}

\gl{TODO: intérêt des représentations sparses}

\subsection[Proposition d'un algorithme]{Proposition d'un algorithme de recouvrement de similarités acoustiques basé sur une approche objet}
\label{sec:ch8_algoObjet}

Comme indiqué dans la section \ref{sec:ch8_intro}, les résultats en perception sonore suggèrent l'opportunité d'une représentation des scènes auditives basée sur l'objet afin d'en prédire les propriétés de haut niveau. La détection d'événements restant un problème ouvert (\cf~Sections~\ref{sec:ch6_dcase2013AED} et~\ref{sec:ch6_dcase2016AED}), nous considérons, dans nos travaux, un schéma simple de quantification, aussi générique que possible. 

Dans cette approche, il s'agit de grouper les régions de la scène sont qui sont cohérentes. Le regroupement se fait en utilisant l'algorithme de \emph{clustering} $k$-means.

Étant donné un ensemble de descripteurs à $d$-dimensions $x_l^u\in X_u$, $l=\lbrace 1,2,\ldots,L\rbrace$, extrait de la scène  $s_u$, $u=\lbrace 1,2,\ldots,U\rbrace$, l'objectif de $k$-means est de partitionner $X_u$ en $M$ groupes, appelés clusters, $c^u_m\in C_u$, $m=\lbrace 1,2,\ldots,M\rbrace$. Le partitionnement se fait en minimisant pour chaque cluster l'erreur quadratique entre sa moyenne empirique (centroïde) et les points contenus. Compte tenu de $\mu_m^u$ le centroïde du cluster $c_m^u$, $k$-means tente de minimiser la fonction objectif suivant:

\begin{equation}
J(C_u)=\sum\limits_{m} \sum_{x^u_l\in c^u_m} \Vert x_l^u - \mu_m^u \Vert^2\mbox{.}
\end{equation}

Chaque scène $s_u$ est alors décrite par un ensemble de clusters $C_u$. Il convient de noter que cette approche de quantification diffère des schémas d'apprentissage non-supervisés tels que ceux étudiés dans \cite{bisot2016acoustic}, où les descripteurs de la scène sont projetés dans un dictionnaire appris sur l'ensemble des données.

Ici, dans le but de mieux équilibrer l'influence sur la décision finale des événements sonores saillants, d'une part, et des sons de texture, d'autre part, la similitude entre deux scènes est calculée sur la base de la similitude entre leurs centroïdes.

La similarité entre tous les centroïdes des scènes $\mu_i$, $i=\lbrace1,2,\ldots,I \rbrace$ avec $I=UM$, est calculée en utilisant une fonction à base radiale (RBF: \emph{radial basis function}). L'ensemble des similarités forme le noyau $K$. Les paramètres de la fonction RBF sont mis à l'échelle localement, en suivant la méthodologie proposée par \citep{selfTuneManor2004}:

\begin{equation}
\label{eq:kc}
K_{ij} = \exp\left( - \dfrac{\Vert \mu_i - \mu_j \Vert^2}{\Vert \mu_i - \mu_{k,i} \Vert \Vert \mu_j - \mu_{k,j} \Vert} \right) 
\end{equation} 

où $\mu_{k,i}$ et $\mu_{k,j}$ sont respectivement les $m$ème plus proches voisins des centroïdes $\mu_i$ et $\mu_j$. $\Vert \cdot \Vert$ désigne la norme euclidienne.

Pour calculer la similarité entre deux scènes, nous considérons alors plusieurs métriques de similarité basées sur différentes combinaisons des centroïdes:

\begin{itemize}
\item \emph{ob-closest} (ob-c): la similarités entre deux scènes est égale à la plus grande similarité entre leurs centroïdes;
\item \emph{ob-averaged} (ob-a): la similarités entre deux scènes est égale à la moyenne des similarités entre leurs centroïdes;
\item \emph{ob-weighted} (ob-w): pour chaque scène, chaque centroïde est pondéré en fonction du nombre de trames appartenant au cluster. L'ensemble formé des centroïdes et de leurs poids respectifs est appelé une signature. Chaque scène $s_u$ est ainsi décrite par une signature $p_u$ de $M$ clusters ($p_u=\lbrace(\mu_1^u,w_1^u),(\mu_2^u,w_2^u),\ldots,(\mu_M^u,w_M^u)\rbrace$), avec $\mu_m^u$ et $w_m^u$ étant respectivement les centroïdes et les poids du $m$ème cluster. L'ensemble des poids correspondant aux clusters d'une scène peut être vu comme un histogramme. La similarité entre deux scènes est alors la similarité entre leurs signatures, celle-ci devant tenir compte de la similarité entres leurs histogrammes de poids, ainsi que de la similarité entre leurs centroïdes.
\end{itemize}

Concernant \emph{ob-w}, un moyen communément utilisé pour mesurer la distance entre deux signatures est l'earth mover's distance ($\EMD$). 

L'$\EMD$ calcule la distance entre deux histogrammes non-alignés en trouvant le coût minimal à payer pour transformer un histogramme dans l'autre. L'alignement des histogrammes s'effectue à partir d'une ``\,distance d'ancrage\,'' (\emph{ground distance}). Cette dernière est la distance entre les représentants des points (\emph{bin}) des histogrammes. Les représentants peuvent prendre plusieurs formes, en fonction de l'application considérée. Dans notre cas, les histogrammes sont formés par les poids $w^u$ des clusters, chaque point de l'histogramme illustrant le poids d'un cluster. Les représentants des points (clusters) sont alors définis par les centroïdes $\mu^u$ des clusters.

Dans nos travaux, nous utilisons une version alternative de l'$\EMD$, introduite par \citep{pele2008linear}, et appelée $\widehat{\EMD}$. Cette dernière est adaptée pour des histogrammes non-normalisés.

Pour calculer l'$\widehat{\EMD}$, nous utilisons la procédure proposée dans \citep{pele2009fast}. Compte tenu des deux signatures $p_u$ et $p_v$, composées, chacune, de $n$ et $m$ clusters, l' $\widehat{\EMD}$ est obtenue en résolvant le programme linéaire suivant:

\begin{equation}
\begin{split}
\widehat{\EMD}(p_u,p_v) &=\left( \min\limits_{\lbrace f_{nm}\rbrace} \sum\limits_{n,m} f_{nm}D_{nm}^{uv} \right) \\
&+ \left|\sum\limits_{n} w_n^u - \sum\limits_{m} w_m^v  \right| \alpha \max\limits_{n,m}\lbrace  D_{nm}^{uv}\rbrace.
\end{split}
\end{equation}

\begin{equation*}
\mathrm{s.t.} \quad f_{nm}\geq0 \quad \sum\limits_{m} f_{nm} \leq w_n^u \quad \sum\limits_{n} f_{nm} \leq w_m^v
\end{equation*}

\begin{equation*}
\sum\limits_{n,m}f_{nm} = \min\left( \sum\limits_{n} w_n^u ,\sum\limits_{m} w_m^v \right)
\end{equation*} 

où  $\lbrace f_{nm} \rbrace$ est le flux entre les poids $w_n^u$ et $w_m^v$, soit le montant transporté du $n$ème cluster afin de  ``\,répondre à la demande\,'' du $m$ème cluster. On note $D^{uv}$ la ``\,distance d'ancrage\,'', une matrice contenant les distances entre les groupes de centroïdes  $\mu^u$ et $\mu^v$ des deux signatures $p_u$ et $p_v$. 

Formellement, $D^{uv}$ est calculée à partir du noyau $K$:

\begin{equation}
D^{uv}=\boldsymbol{1}-K^{(uv)}
\end{equation}

avec $K^{(uv)}$ la partie de $K$ contenant les similarités entre les groupes de centroïdes $\mu^u$ et $\mu^v$. Comme suggéré dans \citep{pele2009fast}, nous définissons le paramètre compromis $\alpha$ à $1$.

La mesure de similarité finale entre les scènes $s_u$ et $s_v$ est obtenue à l'aide d'un noyau Gaussien étendu $K^s$  \citep{chapelle1999support,jing2003support}:

\begin{equation}
\label{eq:ks}
K_{uv}^s = \exp\left( - \dfrac{\widehat{\EMD}(p_u,p_v)}{A} \right) \\
\end{equation}

avec $A$ un paramètre de mise à l'échelle, égal à la valeur moyenne des $\widehat{\EMD}$ calculée entre toutes les scènes. Le noyau $K^s$ résultant est appelé noyau $\EMD$. Il convient de noter qu'il n'y a aucune garantie que ce noyau soit défini positif.

\section[Évaluation de l'approche objet]{Évaluation de l'approche objet pour le recouvrement des similarités acoustiques}

\subsection{Objectif}

\gl{TODO: parler de Intégration \emph{early} \vs \emph{late}}

The \emph{ob} approaches are compared to commonly used early integration approach (\emph{early}).

\gl{TODO: ici expliquer pourquoi on ne parle pas de classification}

\subsection{Banque de données}

L'expérience est menée sur le corpus de scènes enregistrées utilisé dans le cadre de la tâche 1 (ASC) du challenge DCASE 2013 \citep{giannoulis2013detection,Giannoulis2013database,Stowell15}.

Ce corpus se décompose en deux parties, une partie publique (corpus de développement), et une partie privée (corpus d'évaluation). Chacune des parties est composée de 100 enregistrements de 30 secondes de différentes scènes acoustiques. Les 100 enregistrements sont divisés en 10 classes de scènes acoustiques (10 scènes par classe). Ces classes sont présentées dans le tableau~\ref{tab:classASCDcase2013}. 

Pour construire ce corpus, trois preneurs de sons ont visité une grande variété d'endroits de la capitale Britannique Londres, sur une période de plusieurs mois. Une attention particulière a été portée afin de garantir qu'il n'existe pas de variations systématiques des caractéristiques des enregistrements, en fonction du type de scènes. Tous les enregistrements ont été effectués dans des conditions météorologiques modérées, à des moments de la journée et/ou de la semaine variables, et chaque preneur de sons a du enregistrer tous les types de scènes. 

En conséquence, le corpus ASC du challenge DCASE 2013 bénéficie d'une diversité intra-classe intéressante, tout en restant gérable en terme de taille, ce qui convient pour une évaluation approfondie des choix de conception des algorithmes en ASC et ASSR \citep{lagrange2015bag}.

\begin{table}[t]
\centering
\begin{tabular}{cc}
\multicolumn{2}{l}{classes} \\
\hline 
autobus             & rue calme \\ 
marché en plein air & parc            \\                      
rue animée          & restaurant \\ 
bureau              & supermarché \\ 
station de métro    & métro \\ 
\hline
\end{tabular}
\vspace{0.5mm}
\caption{Classes de scènes sonores considérées dans le cadre de la tâche 1 (ASC) du challenge DCASE 2013.}
\label{tab:classASCDcase2013}
\end{table}

\subsection{Descripteurs}

Les expériences sont réalisées en utilisant deux descripteurs:

\begin{itemize}
\item les coefficients de \emph{scattering}: pour le \emph{scattering} (\cf~Section~\ref{sec:ch6_scattering}) chaque scène de $30$ secondes est décrite par $128$ vecteurs de coefficients calculés avec des fenêtres $\boldsymbol{\phi}(t)$ d'une durée $T=372\,\mathrm{ms}$, en considérant un recouvrement de $50\%$. Seules $24$ secondes des scènes sont considérées, en effet, $3$ secondes sont éliminées au début et à la fin de la scène pour éviter des artefacts dû à des effets de bords. Les expériences sont menées avec et sans compression logarithmique (\cf~Section~\ref{sec:ch6_LogComp});
\item les MFCCs:  pour les MFCCs (\cf~Section~\ref{sec:ch6_mfcc}), nous utilisons des fenêtres de $50\,\mathrm{ms}$, avec un recouvrement de $50\%$. L'ensemble du spectre fréquentiel est considéré. Différents rangs de coefficients ont été testés pour calculer les MFCCs. Les résultats rapportés ici ne le sont que pour le meilleur réglage, incluant 40 coefficients, dont le premier, lié à l'énergie moyenne. Ces paramètres nous donnent $600$ vecteurs de descriptions par scène. Pour obtenir une représentation plus robuste, une étape de sous-échantillonnage (\emph{pooling}) est effectuée sur les vecteurs\citep{Tzanetakis2002musical}. Chaque enregistrement est divisé suivant des fenêtres de $250\,\mathrm{ms}$, sans considérer de recouvrement. Pour chacune des fenêtres, les vecteurs de descripteurs sont moyennés point à point, réduisant ainsi le nombre de vecteurs de description par scène à $120$. Outre améliorer la robustesse de la représentation, cette étape nous permet encore d'équilibrer le nombre de vecteurs de description entre les MFCCs et le \emph{scattering}, et, ce faisant, de rendre plus équitables les comparaisons.
\end{itemize}

\subsection{Systèmes évalués}

Nous nous plaçons dans un cadre non-supervisé (ASSR), l'objectif étant de retrouver les similarités existantes entre les scènes du corpus d'évaluation du challenge DCASE 2013. Ces similarités découlant de l'appartenance des scènes aux classes considérées (\cf~Table~\ref{tab:classASCDcase2013}).

Concernant les conditions expérimentales, nous évaluons l'influence du type d'approches (\emph{early} \vs~\emph{ob}), et du type de descripteurs (MFCC \vs~\emph{scattering}). Plus précisément:

\begin{itemize}

\item quatre approches sont comparées:

\begin{itemize}
\item \emph{early};
\item \emph{ob-closest};
\item \emph{ob-averaged};
\item \emph{ob-weighted};
\end{itemize}

\item ainsi que trois descripteurs:

\begin{itemize}
\item \emph{MFCC};
\item \emph{scattering}: coefficients de scattering sans compression logarithmique;
\item \emph{log-scattering}: coefficients de scattering avec compression logarithmique.
\end{itemize}
 
\end{itemize}

\subsection{Paramètres}

Pour les approches \emph{ob}, les similarités sont définies par les noyaux introduits à la section \ref{sec:ch8_algoObjet}. L'étape de \emph{clustering} est effectuée à l'aide de l'algorithme $k$-means$++$ \citep{arthur2007k}, une version augmentée de l'algorithme $k$-means profitant d'un procédure d'initialisation plus robuste. trois nombres de clusters $M$ sont considérés, nommément $8$, $16$ et $32$.

Pour les approches \emph{early}, deux noyaux sont considérés pour calculer les similarités: un noyau linéaire, et un noyau Gaussien. Pour le noyau, Gaussien, nous utilisons la même méthode de mise à l'échelle locale, réglée en fonction du nombre de plus proches voisins $k$ (\cf~Équation~\ref{eq:kc}), que celle utilisée pour les approches \emph{ob} (\cf~Section~\ref{sec:ch8_algoObjet}), et introduite dans \citep{selfTuneManor2004}.

\subsection{Métriques et analyse}
 
La métrique utilisée est la précision au rang $k$ ($P@k$), précédemment introduite aux sections~\ref{sec:ch5_methodoEtStat1} et~\ref{sec:ch6_metriqueASSR}. La $P@k$ est calculée pour $k=\lbrace 1,\ldots,9\rbrace$, étant donné que chaque classe est composée de seulement $10$ scènes. À noter que la $P@1$ est équivalente à une mesure de précision (\emph{accuracy}) obtenue par un classifieurs pour lequel l'appartenance d'un item à une classe se décide suivant le label du plus proche voisin.

Pour chaque condition expérimentale, nous ne rapportons que les résultats obtenus avec le jeu de paramètres, \emph{ie} le nombre de clusters $M$ pour les approches \emph{ob}, le paramètre de mise à l'échelle $k$ des noyaux RBF (\cf~Équation~\ref{eq:kc}) conduisant à la meilleur $P@9$.

Dans cette étude, nous considérons qu'un système A présente de meilleures performances qu'un système B si l'ensemble des $P@k$ ($k=\lbrace 1,\ldots,9\rbrace$) du système A est supérieur aux $P@k$ du système B.

\subsection{Résultats}

\begin{figure}[t]
\begin{center}
\includegraphics[width=.9\columnwidth]{gfx/ch_8/unsupervised_test2-eps-converted-to}
\caption{Acoustic scene similarity retrieval (ASSR) in the DCASE 2013 private dataset: precisions at rank $k$ ($P@k$) obtained for MFCCs and scattering with logarithmic compression, as a function of the rank $k$.}
\label{fig:ASS_1}
\end{center}
\end{figure}

\begin{figure}[t]
\begin{center}
\includegraphics[width=.9\columnwidth]{gfx/ch_8/unsupervised_test1-eps-converted-to}
\caption{Acoustic scene similarity retrieval (ASSR) in the DCASE 2013 private dataset: precisions at rank $k$ ($P@k$) obtained for scattering coefficients, with and without logarithmic compression, as a function of the rank $k$.}
\label{fig:ASS_2}
\end{center}
\end{figure}

Les $P@k$ pour les différentes conditions expérimentales considérées sont affichés sur les figures~\ref{fig:ASS_1} et~\ref{fig:ASS_2}.  La figure~\ref{fig:ASS_1} illustre l'influence des approches (\emph{early} \vs~\emph{ob}), et des descripteurs  (MFCC \vs~\emph{scattering}). La figure~\ref{fig:ASS_1}, elle, rend compte de l'effet de la compression logarithmique sur les coefficients de \emph{scattering}.

\subsubsection{MFCC \vs~scattering}


Quel que soit le rang $k$ considéré, le meilleur résultat est obtenu pour les coefficients de \emph{scattering} avec une compression logarithmique en utilisant l'approche \emph{ob-c}. 

Dans l'ensemble, les coefficients \emph{log-scattering} surpassent systématiquement MFCCs. La capacité du \emph{scattering} à capturer des modulations à grande échelle améliore ainsi nettement les performances, par opposition aux MFCCs, qui ne décrivent qu'une enveloppe spectrale de courte durée.\\

On constate que la compression logarithmique améliore fortement les résultats pour le \emph{scattering}, en particulier pour les approches \emph{ob}, qui obtiennent des résultats inférieurs à ceux de \emph{early} pour des coefficients de \emph{scattering} sans compression logarithmique (\cf~Figure~\ref{fig:ASS_2}).

\subsubsection{Approche objet \vs~early}

Pour le \emph{scattering}, les performances des deux approches \emph{ob-c} et \emph{ob-w} surpassent celles de \emph{early}, confirmant ainsi les avantages de l'utilisation d'une représentation à base d'objets, pour affiner les mesures de similarité entre les scènes. 

Cependant, il convient de noter que les performances de \emph{ob-a} sont similaires à celles de \emph{early}. Ce fait tend à montrer que l'information discriminante est détruite par le moyennage des contributions de tous les centroïdes. Afin de pouvoir bénéficier d'une représentation à base d'objets, il est nécessaire de ne sélectionner que certains centroïdes représentatifs, lorsqu'on les compare entre eux.

En outre, il apparaît que \emph{ob-c} est plus à même de recouvrer les similarités que \emph{ob-w}. Cette dernière observation suggère que la pondération des clusters, en fonction du nombre de trames qu'ils contiennent, peut se révéler être une solution limitée. Rien n'indique, en effet, que l'information discriminante entre deux scènes soit contenue au sein de la majorité de leurs trames. Au contraire, ces résultats semblent montrer que deux environnements de deux classes différentes peuvent partager un grand nombre de sources sonores similaires, la discrimination ne s'opérant que sur certaines.

Les mêmes observations sont faites pour les MFCCs pour un $k\leq5$. Cependant, pour un rang $k$ supérieur $5$, toutes les approches objet affichent des résultats semblables. Cela peut être dû au fait que, à un moment donné, les MFCCs ne parviennent plus à faire la distinction entre les différents événements d'une scène, mélangeant ainsi les éléments discriminants, et ceux non informatifs. {Dans ce cas, l'étape de \emph{clustering} visant à regrouper les informations similaires est inutile.

\subsection{Discussion}

\gl{TODO}
%*****************************************
%*****************************************
%*****************************************
%*****************************************
%*****************************************




